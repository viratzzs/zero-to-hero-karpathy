{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62f50bf7",
   "metadata": {},
   "source": [
    "## Creating Bigram dataset for training NN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbe3d7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a29ada7",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open(\"names.txt\", \"r\").read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d41b4c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26, '.': 0}\n",
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(\"\".join(words))))\n",
    "str_to_int = {str: (int + 1) for int, str in enumerate(chars)}\n",
    "str_to_int['.'] = 0\n",
    "print(str_to_int)\n",
    "int_to_str = {int: str for str, int in str_to_int.items()}\n",
    "print(int_to_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "12c9daaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = [], []\n",
    "for w in words[:1]:\n",
    "    w = ['.'] + list(w) + ['.']\n",
    "    for c1, c2 in zip(w, w[1:]):\n",
    "        ix1, ix2 = str_to_int[c1], str_to_int[c2]\n",
    "        #print(c1, c2)\n",
    "        xs.append(ix1)\n",
    "        ys.append(ix2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82aca55b",
   "metadata": {},
   "source": [
    "We can either use tensor() or Tensor(), the latter casts the type to float while torch.tensor() can let you specify your own data type which seems to be ideal!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aaa146a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fd2880c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  5, 13, 13,  1]) torch.Size([5])\n",
      "tensor([ 5, 13, 13,  1,  0]) torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "print(xs, xs.shape)\n",
    "print(ys, ys.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bf672e",
   "metadata": {},
   "source": [
    "### One hot encoding input vectors\n",
    "We do this because feeding direct integers into NNs is considerably stupido and can lead to some weird internal math."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5181ed71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0.]]) torch.Size([5, 27])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "xenc = F.one_hot(xs, num_classes=27).float() # we feed in float ints as input due to decimals, num_classes is 27 because that's our vocab length\n",
    "print(xenc, xenc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "43df3547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(xenc) # shows active bits and their respective indices\n",
    "print(xenc.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c217f2d",
   "metadata": {},
   "source": [
    "## Creating Linear layer of neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9019512d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([27, 1])\n"
     ]
    }
   ],
   "source": [
    "W = torch.randn((27, 1)) # creates a random array sampled from normal distribution\n",
    "print(W.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f90ba4ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3187],\n",
       "        [ 0.1267],\n",
       "        [-0.4235],\n",
       "        [-0.4235],\n",
       "        [-1.3128]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc @ W # (5, 27) @ (27, 1) -> (5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "74bde5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([27, 27])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3223e+00,  2.6850e-01, -7.0959e-01, -1.2964e-01,  8.8928e-01,\n",
       "         -1.6973e+00, -1.4297e+00,  7.4506e-01, -2.1140e+00,  6.5900e-01,\n",
       "          9.8205e-01,  2.1172e-01,  2.5629e+00,  9.5920e-01,  1.9193e+00,\n",
       "          9.9940e-02, -7.0862e-01,  4.7327e-01,  1.0120e+00, -1.0512e+00,\n",
       "          9.3161e-01,  1.1303e-01,  1.0594e-01, -2.3912e-01,  1.1997e+00,\n",
       "          3.1005e-02, -5.9222e-01],\n",
       "        [ 6.3097e-01,  1.1864e+00,  6.1837e-01, -2.4345e-01,  2.8295e-01,\n",
       "          2.2870e+00,  1.0538e+00, -2.4559e-01, -6.7456e-01,  6.5415e-01,\n",
       "         -1.5692e-01,  1.9564e-01, -1.1862e+00, -1.2564e+00, -2.2682e+00,\n",
       "          7.2464e-01, -3.6260e-01, -9.7481e-01, -1.1651e+00,  8.8844e-01,\n",
       "         -3.3128e-01,  5.6318e-01, -2.8333e-01, -2.0064e-01, -9.5221e-02,\n",
       "          5.0983e-01, -6.9077e-01],\n",
       "        [ 4.3261e-01, -3.5901e-01, -1.9060e+00, -9.5987e-01,  2.7549e-01,\n",
       "         -8.6135e-01, -1.7245e+00, -1.7481e+00, -1.4757e+00, -5.4727e-01,\n",
       "          9.9468e-01, -6.7480e-02,  7.1483e-02,  1.4872e-01, -8.3531e-01,\n",
       "          7.1744e-01,  1.7122e+00,  1.2672e-01,  1.0603e+00, -1.1222e+00,\n",
       "         -8.1159e-01,  2.9211e-01,  4.5737e-01,  1.9839e+00, -1.1495e+00,\n",
       "         -1.9802e-01, -1.2337e+00],\n",
       "        [ 1.1248e-01, -4.5088e-01, -4.4189e-01, -3.5434e-01, -3.7041e-01,\n",
       "         -1.2447e-01,  2.0545e-01, -7.0955e-02, -6.7204e-01, -3.0004e-01,\n",
       "          5.4951e-01, -2.0492e+00, -2.6311e+00, -9.0187e-01, -2.3026e+00,\n",
       "          1.5181e-01,  3.6744e-01, -1.0804e+00, -1.1394e-01, -2.9653e-01,\n",
       "         -1.9736e-01, -6.4931e-01, -3.1155e-01, -2.8752e-02, -6.0210e-01,\n",
       "         -2.3759e-01, -3.4870e-01],\n",
       "        [-1.1089e+00,  1.6252e+00,  9.0730e-01, -1.9988e+00,  8.1344e-01,\n",
       "          1.2735e+00,  2.4710e-01, -2.6646e-01,  8.7226e-01, -7.7909e-01,\n",
       "          1.5442e+00, -1.1362e-02, -1.9597e-01,  1.6193e+00,  1.8804e+00,\n",
       "         -9.3042e-01, -2.2310e+00, -6.9733e-01, -1.1135e+00,  2.4020e-01,\n",
       "         -2.2772e-01,  1.8305e+00,  1.3661e+00, -6.0935e-01,  2.4105e-01,\n",
       "         -1.6393e+00,  1.7604e+00],\n",
       "        [ 5.5812e-01, -7.9016e-01,  5.8054e-01,  1.1289e+00, -2.5363e-01,\n",
       "         -1.4785e-01,  5.9503e-01, -4.4608e-01, -4.0936e-01,  6.7105e-01,\n",
       "         -8.0093e-01,  1.6156e+00,  6.8763e-01, -1.7561e+00, -1.9011e-01,\n",
       "         -4.8982e-01, -7.7972e-02,  3.1064e-01,  3.6353e-01, -4.1992e-01,\n",
       "         -7.5291e-01, -1.9308e-01, -9.3431e-02, -1.0112e+00,  8.6650e-01,\n",
       "          7.4063e-01,  4.9066e-01],\n",
       "        [ 4.7994e-01,  7.1548e-01,  6.8164e-01, -7.1395e-01, -1.3966e+00,\n",
       "          8.2442e-01, -1.0760e+00, -1.2565e+00, -5.5208e-01,  1.7517e+00,\n",
       "          2.3037e+00, -9.5163e-01, -3.0027e+00,  4.8902e-01,  2.0055e-01,\n",
       "          7.4196e-01, -1.1493e+00,  5.0432e-01,  7.6180e-01,  3.7349e-01,\n",
       "         -1.4568e-01, -7.1883e-01, -1.3719e+00,  2.6612e-01,  9.0220e-01,\n",
       "          9.3931e-01, -8.1099e-01],\n",
       "        [-2.6872e+00,  1.2770e+00,  1.1426e-01,  6.3092e-02,  8.5711e-01,\n",
       "          7.4554e-01,  9.4302e-01,  3.7631e-01,  1.4449e+00, -1.5991e+00,\n",
       "          5.6328e-01,  1.2021e-01,  6.1089e-01, -8.2480e-01,  1.0013e+00,\n",
       "          3.7215e-02, -1.4016e+00, -7.5281e-01,  1.4339e+00,  4.7316e-01,\n",
       "         -1.8640e+00,  9.6248e-01, -1.2313e+00,  4.3657e-01, -7.9883e-01,\n",
       "          1.5722e+00, -3.4623e-01],\n",
       "        [-3.8269e-01, -1.0551e+00,  1.4925e-01,  8.4277e-01,  1.1798e-01,\n",
       "         -1.2218e+00,  1.4977e+00, -9.8687e-01, -2.9817e-01,  1.1251e+00,\n",
       "          7.1835e-01,  9.1763e-01,  2.8331e-02,  7.6833e-01, -3.0067e-02,\n",
       "          3.8946e-01, -1.0976e+00, -1.1385e+00,  2.6576e-01, -3.2610e-01,\n",
       "          2.2447e-01, -3.9809e-01,  2.3368e+00,  1.1217e+00, -9.8893e-01,\n",
       "         -1.3156e+00, -8.3885e-01],\n",
       "        [ 1.5659e-01, -1.4862e-01, -4.2235e-01,  2.5577e-01, -6.8985e-02,\n",
       "         -8.9402e-01, -9.8044e-01, -1.2347e+00,  9.0426e-02, -7.1326e-01,\n",
       "          8.9987e-02, -6.9594e-01, -5.0912e-01, -1.7430e+00, -4.3836e-01,\n",
       "          1.0975e+00, -1.1746e-01, -1.6325e+00,  1.6632e+00, -3.0160e-01,\n",
       "          1.5073e-01, -9.6142e-01, -1.8487e-01,  1.1419e+00, -6.0245e-02,\n",
       "         -1.1819e-01, -5.1245e-01],\n",
       "        [ 3.3167e-01, -3.2202e-01, -6.0266e-02, -6.0973e-01,  1.9142e+00,\n",
       "          8.6679e-01, -1.6693e+00,  2.6851e-01, -5.1388e-01,  6.0041e-01,\n",
       "          4.7228e-01, -1.3951e+00, -1.6090e+00,  1.4295e+00, -1.7321e-01,\n",
       "          2.2626e-01,  1.8893e+00,  7.3323e-01, -4.8812e-01,  1.6797e-01,\n",
       "         -7.2275e-01, -1.8894e+00, -1.2786e+00, -5.3178e-01,  2.5238e-01,\n",
       "          1.2945e+00, -4.3875e-01],\n",
       "        [-5.6040e-01,  1.0460e+00,  1.0827e+00,  5.1877e-01,  8.1292e-01,\n",
       "         -6.8912e-01,  1.0025e+00, -7.6679e-01, -3.7335e-01, -3.6996e-01,\n",
       "         -3.5215e-01, -7.9707e-01,  2.0141e+00, -1.7645e-01,  3.4291e-01,\n",
       "         -1.5251e-01, -1.4511e+00,  4.3587e-01, -6.0552e-01,  1.2722e+00,\n",
       "          3.6153e-01, -2.6065e-01, -4.5520e-01,  8.7797e-01,  9.2467e-02,\n",
       "          5.8002e-01, -4.9175e-01],\n",
       "        [-7.6594e-01,  2.8974e-01,  1.1932e+00,  2.3073e+00, -7.9471e-01,\n",
       "          1.6511e+00, -8.8829e-01,  2.2273e-01,  1.6929e-01,  1.1375e+00,\n",
       "          1.0202e+00, -6.6942e-02, -5.3841e-01, -6.7888e-03, -9.8718e-01,\n",
       "          1.7195e+00,  1.2440e+00, -9.7357e-02,  7.0278e-01, -9.0852e-01,\n",
       "         -2.8690e-01,  6.7060e-02,  7.8851e-01, -1.0359e+00, -9.4753e-01,\n",
       "          1.0776e+00, -1.2983e-01],\n",
       "        [-1.6279e+00,  2.0483e+00,  6.8948e-01,  2.3550e+00,  2.9720e+00,\n",
       "          3.6592e-01, -2.9488e-02, -5.6258e-01,  1.4675e+00,  5.7486e-01,\n",
       "          6.8481e-01,  9.1782e-01,  1.2187e+00,  1.6432e+00, -1.5518e+00,\n",
       "         -8.4052e-01,  3.7518e-01, -3.7582e-01,  1.2756e-01,  2.6086e+00,\n",
       "          5.7150e-03, -9.8368e-01, -1.0406e+00, -4.0486e-01,  1.2307e+00,\n",
       "         -8.3753e-01, -1.7227e+00],\n",
       "        [-2.8387e-01, -7.7024e-02,  1.3886e+00, -1.5358e+00,  2.5880e-01,\n",
       "         -5.8710e-01,  6.3504e-01, -7.2655e-01,  7.7856e-01, -3.9516e-01,\n",
       "          1.0925e+00,  1.3812e-02, -2.0234e-01, -3.9534e-01,  4.6669e-01,\n",
       "          7.4384e-01, -3.8481e-01,  1.3550e+00,  1.0087e-01,  2.0650e+00,\n",
       "         -8.6073e-01,  4.7688e-01,  1.2081e+00, -8.2794e-02, -7.4644e-01,\n",
       "         -9.3461e-02, -5.1853e-01],\n",
       "        [ 6.1050e-01, -1.0928e+00,  1.1672e+00, -1.0127e+00,  9.0900e-01,\n",
       "         -7.2760e-02,  8.6748e-01, -1.2776e+00,  2.1081e+00, -2.7669e-01,\n",
       "         -2.7978e-01,  4.0745e-01, -9.5010e-01, -9.7571e-01, -1.0524e+00,\n",
       "          1.0643e+00, -3.4842e-02,  3.1433e+00,  6.0132e-01, -1.2065e-01,\n",
       "         -2.1039e+00,  1.5012e-01,  3.4736e-01, -1.6217e+00, -1.0350e+00,\n",
       "          6.0917e-01, -1.3517e-01],\n",
       "        [ 6.7223e-01, -1.1645e+00, -1.9370e+00, -2.8335e-01, -7.5044e-01,\n",
       "         -6.5815e-01,  1.7849e-01, -1.7650e+00,  1.3613e+00, -4.8715e-01,\n",
       "         -2.4348e+00, -1.1988e+00,  5.1202e-01, -1.3317e+00, -1.4284e+00,\n",
       "         -5.9460e-01, -3.3442e-01,  4.0603e-01, -5.6291e-01,  4.8250e-01,\n",
       "          8.4407e-01,  1.9461e-01, -2.0866e+00, -1.0843e+00, -5.8171e-01,\n",
       "         -3.3539e-01,  8.2841e-01],\n",
       "        [ 3.3497e-01,  2.1823e-01, -4.4847e-01, -1.5019e+00,  1.8839e-01,\n",
       "         -3.4958e-01, -1.0749e+00, -3.2272e-01, -8.0530e-01,  1.7301e-01,\n",
       "          1.1922e+00, -5.3621e-01,  7.0636e-01,  1.2870e+00, -9.2875e-01,\n",
       "         -2.5797e-01, -1.5674e+00, -5.6149e-01,  1.0675e+00, -1.9559e+00,\n",
       "         -4.7893e-01, -9.8206e-01,  1.6888e+00, -2.2314e-01,  1.2526e+00,\n",
       "         -7.7057e-02,  8.8881e-01],\n",
       "        [ 1.2460e+00,  1.2072e+00,  6.2208e-01, -6.2065e-01, -1.3782e+00,\n",
       "         -1.0735e+00,  8.7836e-01,  5.0993e-01,  6.7418e-01,  7.0677e-01,\n",
       "         -1.6688e-01, -2.4785e+00,  2.3781e-01, -1.8085e-01,  2.1271e-01,\n",
       "          1.8891e-01, -8.8717e-01, -4.9325e-01, -9.5829e-01,  1.5009e+00,\n",
       "         -3.4592e-01, -6.4920e-01,  2.0518e-01,  1.9829e-01, -4.1026e-01,\n",
       "         -7.1434e-01,  1.6306e+00],\n",
       "        [ 6.3998e-01, -4.3583e-01,  1.6868e-01,  9.6640e-01, -3.0681e-01,\n",
       "         -1.0289e+00, -3.3399e-01, -2.1075e-01,  7.9182e-01, -1.1900e+00,\n",
       "          4.4294e-01,  5.7638e-01,  1.7736e+00,  1.7011e+00,  9.6964e-01,\n",
       "          4.2129e-02,  2.2030e+00,  6.0753e-01,  9.5128e-01, -1.0074e+00,\n",
       "         -7.6436e-01, -1.2322e+00,  1.0505e+00, -1.8945e+00,  5.8342e-01,\n",
       "         -2.5625e-01,  9.4898e-01],\n",
       "        [ 4.8634e-01,  4.7829e-01,  1.0614e-01, -5.3276e-03,  6.1353e-01,\n",
       "          1.0311e+00, -9.4436e-01,  7.0552e-01,  2.2659e-01,  1.2165e+00,\n",
       "         -6.7987e-01,  1.0747e+00, -4.1632e-01, -6.3597e-01, -2.7052e-01,\n",
       "          1.2636e+00, -9.3455e-01, -1.5868e+00,  7.0502e-01, -2.1134e-01,\n",
       "          1.8249e+00,  2.3898e-01, -2.1816e+00, -6.0465e-01, -5.2274e-01,\n",
       "         -1.5553e+00, -9.6179e-02],\n",
       "        [ 4.1639e-01,  3.6224e-01, -1.5667e+00,  7.6868e-01,  7.0765e-01,\n",
       "         -6.9589e-01,  5.6396e-01,  1.4231e+00,  1.0995e+00, -1.0647e+00,\n",
       "          1.2235e+00,  4.0095e-01,  1.3336e+00,  1.1029e+00, -4.4552e-01,\n",
       "         -1.7073e+00,  1.0928e+00, -2.7377e-01,  1.2776e+00, -1.2263e+00,\n",
       "          1.2782e+00,  6.4752e-01, -8.5671e-01,  7.6422e-01, -1.3822e+00,\n",
       "          8.3992e-01, -9.1969e-01],\n",
       "        [ 1.8681e-01, -1.8366e+00,  3.9605e-01, -3.2445e-01,  4.0619e-01,\n",
       "         -4.2116e-01,  1.0574e+00, -7.0725e-01,  7.7107e-02, -1.2839e+00,\n",
       "          1.9407e+00,  1.2939e-02, -1.7029e+00,  2.0520e-01,  5.4235e-01,\n",
       "         -1.8572e-01,  1.4610e+00,  2.1560e-01,  3.9612e-01,  4.9398e-01,\n",
       "          7.0579e-01,  9.2563e-01, -4.6760e-03, -7.2006e-01,  1.5744e+00,\n",
       "         -6.2423e-01,  1.5140e+00],\n",
       "        [ 3.6855e-01, -1.2324e+00,  1.3930e-01, -2.7355e-01, -5.7495e-02,\n",
       "         -2.4934e+00,  2.0266e+00,  6.8643e-01,  3.6798e-01,  5.3566e-01,\n",
       "          2.2309e-01, -1.7231e-02, -1.0572e+00,  9.9198e-02,  8.3672e-01,\n",
       "         -1.6810e-03,  1.2751e-01,  1.3892e+00, -5.7693e-01, -1.1654e-01,\n",
       "         -2.3206e+00,  1.1283e+00,  4.2267e-01, -2.9621e-01, -1.0239e-01,\n",
       "          1.6521e+00,  7.4660e-01],\n",
       "        [-1.8890e+00,  1.6185e+00,  1.6984e+00,  1.1666e+00,  6.4753e-01,\n",
       "          3.9121e-01, -1.0437e+00,  9.6235e-01,  3.6870e-01,  9.8878e-01,\n",
       "         -1.5323e-01, -1.4878e+00,  1.0973e+00, -1.7360e+00, -4.2420e-01,\n",
       "          3.3856e-01,  5.6678e-01,  2.1988e+00, -1.1126e+00,  6.4267e-01,\n",
       "          7.4171e-02, -2.9212e-01,  8.3126e-01,  1.5050e-01,  2.7177e-02,\n",
       "         -9.0558e-01, -9.3720e-01],\n",
       "        [ 6.9043e-01, -1.7017e+00, -1.7865e+00,  2.2938e-01, -1.1416e+00,\n",
       "          9.2899e-02, -5.2187e-01,  4.8063e-01, -7.7444e-01, -1.3114e+00,\n",
       "         -1.3207e-01,  2.1260e-01, -3.5547e-01,  4.3620e-01,  1.0499e+00,\n",
       "         -3.7121e-01, -7.0646e-01, -6.6084e-01, -1.7084e+00,  9.1520e-01,\n",
       "         -1.0611e-01,  2.5433e+00,  3.9445e-01, -2.3585e-01,  1.2992e+00,\n",
       "         -6.6539e-01, -1.2293e+00],\n",
       "        [ 7.2827e-01,  1.0711e+00, -8.7565e-01, -1.8875e+00, -2.3572e-01,\n",
       "          2.2546e+00,  8.1810e-01,  2.5390e+00, -8.3540e-01, -1.5878e-01,\n",
       "         -3.6039e-01, -1.2750e+00,  1.2731e+00, -1.1677e+00, -2.3540e+00,\n",
       "         -2.8758e+00,  1.0778e-02,  9.6447e-01,  1.2385e+00,  5.2544e-01,\n",
       "         -8.3119e-01,  9.6485e-01,  9.8380e-01,  4.1764e-01, -9.1618e-02,\n",
       "          2.7145e-01,  3.4857e-01]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = torch.randn((27, 27)) # creates a random array sampled from normal distribution\n",
    "print(W.shape)\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "844613fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7246)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(xenc @ W)[4, 15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71184963",
   "metadata": {},
   "source": [
    "## Transforming nn outputs to probabilities via Softmax!!\n",
    "We need to do this since probabilities must be positive (check e^x's curve, it converts negative inputs to values close to 1 and > than 0) and must sum to be 1, which is what softmax does as it divides exponentiated logits by their sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f346f216",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = xenc @ W # log-counts are something the layers will output for any given input token, these are raw probabilities of sorts\n",
    "counts = logits.exp() # we exponentiate these logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e2c38d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 27])\n",
      "tensor([[ 0.8204,  0.9878,  0.9535,  0.7803,  0.7689,  0.6357,  2.9300,  1.3853,\n",
      "          2.0951,  0.3244,  1.5304,  1.7534,  0.8221,  0.7291,  4.0443,  0.6918,\n",
      "          1.3866,  0.5431,  0.9257,  0.6653,  2.5844,  1.1767,  0.2101,  0.3315,\n",
      "          1.2495,  1.9644,  9.2042],\n",
      "        [ 1.6278,  2.2958,  1.6263,  0.3658,  0.8130,  1.0424,  1.9860,  0.0937,\n",
      "          0.2300,  0.4596,  1.2925,  0.1269,  1.1433,  1.1985,  1.5810,  0.3299,\n",
      "          1.3016,  3.2315,  1.2960,  0.3366,  5.7013,  2.0790,  0.6898,  0.7049,\n",
      "          0.3366,  1.1031,  0.6944],\n",
      "        [ 1.6526,  0.2462,  0.7590,  1.3951,  0.3359,  1.3505,  0.3056,  0.6874,\n",
      "          2.2737,  4.9265,  1.4372,  1.4624,  0.2609,  1.5020,  9.7843,  0.5984,\n",
      "          2.3429,  0.5521,  0.8369,  0.6694,  0.8478,  1.8000,  2.2575,  0.3026,\n",
      "          0.7246,  2.0228,  0.4211],\n",
      "        [ 1.6526,  0.2462,  0.7590,  1.3951,  0.3359,  1.3505,  0.3056,  0.6874,\n",
      "          2.2737,  4.9265,  1.4372,  1.4624,  0.2609,  1.5020,  9.7843,  0.5984,\n",
      "          2.3429,  0.5521,  0.8369,  0.6694,  0.8478,  1.8000,  2.2575,  0.3026,\n",
      "          0.7246,  2.0228,  0.4211],\n",
      "        [ 5.8833,  4.5831,  2.7720,  0.8242,  0.6630,  1.2368,  0.6869,  1.9925,\n",
      "          0.2225,  2.3982,  3.1540,  4.4874,  2.7144,  0.2932,  0.5280,  0.4369,\n",
      "         10.3170,  0.4609,  6.1919,  2.0205,  1.5698,  0.2569,  1.3373,  0.4078,\n",
      "          0.7900,  0.3559,  0.7573]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(counts.shape)\n",
    "counts.sum(1, keepdim=True).shape # get their sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "699b0946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0198, 0.0238, 0.0230, 0.0188, 0.0185, 0.0153, 0.0706, 0.0334, 0.0505,\n",
      "         0.0078, 0.0369, 0.0423, 0.0198, 0.0176, 0.0975, 0.0167, 0.0334, 0.0131,\n",
      "         0.0223, 0.0160, 0.0623, 0.0284, 0.0051, 0.0080, 0.0301, 0.0473, 0.2218],\n",
      "        [0.0483, 0.0682, 0.0483, 0.0109, 0.0241, 0.0309, 0.0590, 0.0028, 0.0068,\n",
      "         0.0136, 0.0384, 0.0038, 0.0339, 0.0356, 0.0469, 0.0098, 0.0386, 0.0959,\n",
      "         0.0385, 0.0100, 0.1692, 0.0617, 0.0205, 0.0209, 0.0100, 0.0327, 0.0206],\n",
      "        [0.0396, 0.0059, 0.0182, 0.0334, 0.0080, 0.0323, 0.0073, 0.0165, 0.0545,\n",
      "         0.1180, 0.0344, 0.0350, 0.0062, 0.0360, 0.2343, 0.0143, 0.0561, 0.0132,\n",
      "         0.0200, 0.0160, 0.0203, 0.0431, 0.0541, 0.0072, 0.0174, 0.0484, 0.0101],\n",
      "        [0.0396, 0.0059, 0.0182, 0.0334, 0.0080, 0.0323, 0.0073, 0.0165, 0.0545,\n",
      "         0.1180, 0.0344, 0.0350, 0.0062, 0.0360, 0.2343, 0.0143, 0.0561, 0.0132,\n",
      "         0.0200, 0.0160, 0.0203, 0.0431, 0.0541, 0.0072, 0.0174, 0.0484, 0.0101],\n",
      "        [0.1026, 0.0799, 0.0483, 0.0144, 0.0116, 0.0216, 0.0120, 0.0347, 0.0039,\n",
      "         0.0418, 0.0550, 0.0783, 0.0473, 0.0051, 0.0092, 0.0076, 0.1799, 0.0080,\n",
      "         0.1080, 0.0352, 0.0274, 0.0045, 0.0233, 0.0071, 0.0138, 0.0062, 0.0132]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 27])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob = counts / counts.sum(1, keepdim=True) # softmax. kaboom, kapow.\n",
    "print(prob)\n",
    "prob.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d2d644",
   "metadata": {},
   "source": [
    "Currently the nn layer is still not quite a nn in full and probs tensor is still a probability matrix. We need hidden layers and non linearities to capture richer patterns. A loss function would be good to train a model as well!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8264ea7",
   "metadata": {},
   "source": [
    "## Implementing loss function at last!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda68b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(25)\n",
    "W = torch.randn((27, 27), generator=g, requires_grad=True) # need to enable requires_grad bcs we gonna backprop thru the n/w for loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18651b2b",
   "metadata": {},
   "source": [
    "### Performing the forward pass!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "35e416b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "xenc = F.one_hot(xs, num_classes=27).float()\n",
    "logits = (xenc @ W)\n",
    "counts = logits.exp()\n",
    "prob = counts / counts.sum(1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "63887d7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0468, grad_fn=<SelectBackward0>),\n",
       " tensor(0.0365, grad_fn=<SelectBackward0>),\n",
       " tensor(0.0525, grad_fn=<SelectBackward0>),\n",
       " tensor(0.0371, grad_fn=<SelectBackward0>),\n",
       " tensor(0.0698, grad_fn=<SelectBackward0>))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if we want to index into probability for each particular token at a position after start token dot(.), manually it goes like this\n",
    "prob[0, 5], prob[1, 13], prob[2, 13], prob[3, 1], prob[4, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6fa7e445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0468, 0.0365, 0.0525, 0.0371, 0.0698], grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# but a better way to do so it is by using torch.arange()\n",
    "prob[torch.arange(5), ys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9ccf1501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.054914951324463"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so, loss function is average of negative log likelihood\n",
    "loss = -prob[torch.arange(5), ys].log().mean()\n",
    "loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb1a84d",
   "metadata": {},
   "source": [
    "### Backward pass time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1782325f",
   "metadata": {},
   "outputs": [],
   "source": [
    "W.grad = None # set gradients to zero before backpropagating each time!\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e02b4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "W.data += -0.1 * W.grad # loss will go down if you run forward pass again!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a309592",
   "metadata": {},
   "source": [
    "## Summing it up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "d889447b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples/bigrams:  228146\n"
     ]
    }
   ],
   "source": [
    "xs, ys = [], []\n",
    "#for w in words[:5]:\n",
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for c1, c2 in zip(chs, chs[1:]):\n",
    "        ix1 = str_to_int[c1]\n",
    "        ix2 = str_to_int[c2]\n",
    "        xs.append(ix1)\n",
    "        ys.append(ix2)\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num = xs.nelement()\n",
    "print(\"Number of examples/bigrams: \", num)\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27, 27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "79f000d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.758953809738159\n",
      "3.371098756790161\n",
      "3.1540417671203613\n",
      "3.020373821258545\n",
      "2.9277119636535645\n",
      "2.860402822494507\n",
      "2.8097293376922607\n",
      "2.7701027393341064\n",
      "2.7380733489990234\n",
      "2.711496591567993\n",
      "2.6890034675598145\n",
      "2.6696884632110596\n",
      "2.6529300212860107\n",
      "2.638277292251587\n",
      "2.6253881454467773\n",
      "2.6139907836914062\n",
      "2.603863477706909\n",
      "2.5948219299316406\n",
      "2.586712121963501\n",
      "2.57940411567688\n",
      "2.572789192199707\n",
      "2.5667762756347656\n",
      "2.5612881183624268\n",
      "2.5562589168548584\n",
      "2.551633596420288\n",
      "2.547365665435791\n",
      "2.5434155464172363\n",
      "2.539748430252075\n",
      "2.5363364219665527\n",
      "2.5331544876098633\n",
      "2.5301806926727295\n",
      "2.5273969173431396\n",
      "2.5247862339019775\n",
      "2.522334575653076\n",
      "2.520029067993164\n",
      "2.517857789993286\n",
      "2.515810966491699\n",
      "2.513878345489502\n",
      "2.512052059173584\n",
      "2.510324001312256\n",
      "2.5086867809295654\n",
      "2.5071346759796143\n",
      "2.5056610107421875\n",
      "2.5042612552642822\n",
      "2.502929210662842\n",
      "2.5016613006591797\n",
      "2.5004522800445557\n",
      "2.4992990493774414\n",
      "2.498197317123413\n",
      "2.497144937515259\n",
      "2.496137857437134\n",
      "2.495173692703247\n",
      "2.4942495822906494\n",
      "2.493363380432129\n",
      "2.4925124645233154\n",
      "2.4916954040527344\n",
      "2.4909095764160156\n",
      "2.4901540279388428\n",
      "2.4894261360168457\n",
      "2.488725185394287\n",
      "2.4880495071411133\n",
      "2.4873974323272705\n",
      "2.4867680072784424\n",
      "2.4861605167388916\n",
      "2.4855728149414062\n",
      "2.4850049018859863\n",
      "2.484455108642578\n",
      "2.4839231967926025\n",
      "2.483408212661743\n",
      "2.4829084873199463\n",
      "2.482424020767212\n",
      "2.481955051422119\n",
      "2.481499195098877\n",
      "2.4810571670532227\n",
      "2.4806275367736816\n",
      "2.480210304260254\n",
      "2.479804754257202\n",
      "2.479410171508789\n",
      "2.4790265560150146\n",
      "2.4786536693573\n",
      "2.478290557861328\n",
      "2.4779367446899414\n",
      "2.477592706680298\n",
      "2.477257251739502\n",
      "2.4769301414489746\n",
      "2.476611852645874\n",
      "2.4763011932373047\n",
      "2.4759981632232666\n",
      "2.4757025241851807\n",
      "2.475414276123047\n",
      "2.475132703781128\n",
      "2.474858045578003\n",
      "2.4745893478393555\n",
      "2.474327802658081\n",
      "2.474071741104126\n",
      "2.4738216400146484\n",
      "2.4735770225524902\n",
      "2.4733383655548096\n",
      "2.47310471534729\n",
      "2.47287654876709\n"
     ]
    }
   ],
   "source": [
    "# Gradient based optimization goes here\n",
    "for k in range(100):\n",
    "    # forward pass\n",
    "    xenc = F.one_hot(xs, num_classes=27).float()\n",
    "    logits = (xenc @ W)\n",
    "    counts = logits.exp()\n",
    "    prob = counts / counts.sum(1, keepdim=True)\n",
    "    loss = -prob[torch.arange(num), ys].log().mean()\n",
    "    print(f\"{loss.item()}\")\n",
    "    \n",
    "    # backward pass\n",
    "    W.grad = None\n",
    "    loss.backward()\n",
    "    \n",
    "    # update\n",
    "    W.data += -50 * W.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff58461e",
   "metadata": {},
   "source": [
    "## Sampling from nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "c7747a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cexze.\n",
      "momasurailezityha.\n",
      "konimittain.\n",
      "llayn.\n",
      "ka.\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(5):\n",
    "    out = []\n",
    "    ix = 0\n",
    "    while True:\n",
    "        xenc = F.one_hot(torch.tensor([ix]), num_classes=27).float() # (1, 27)\n",
    "        logits = xenc @ W\n",
    "        counts = logits.exp()\n",
    "        probs = counts / counts.sum(1, keepdim=True) # fetch probability distribution for next character\n",
    "        \n",
    "        ix = torch.multinomial(probs, num_samples=1, replacement=True, generator=g).item()\n",
    "        out.append(int_to_str[ix])\n",
    "        \n",
    "        if ix == 0:\n",
    "            break\n",
    "\n",
    "    print(\"\".join(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c37ed7",
   "metadata": {},
   "source": [
    "### Notes\n",
    "- One hot encoding essentially does the same as picking up the first character from our lookup table as the first row, so it picks a row from the linear layer of neurons- and then sums up the exponentiated logits across columns to produce a probability distribution!\n",
    "- We can add regularization loss and use it as label smoothing as we did to prevent zero frequency bigrams from ruining the log likelihood by outputting infinite. Essentially has the same effect by pushing the weights closer to zero (add `beta*(W**2).mean()` to the loss to force model to optimize for two objectives. the lower the value of W, the lower the loss) and that leads to an even distribution of probabilities like what happens when we add values >10k to N during label smoothing.\n",
    "- It's hard to maintain a lookup table for more combinations and after a certain number of dimensions for N-gram, it becomes impossible to maintain. So nns offer much more flexibility in that regard!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
